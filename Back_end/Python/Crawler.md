# Crawler

* å‘èµ·è¯·æ±‚ é€šè¿‡ HTTP åº“å‘ç›®æ ‡ç«™ç‚¹å‘èµ·è¯·æ±‚ï¼Œä¹Ÿå°±æ˜¯å‘é€ä¸€ä¸ª Requestï¼Œè¯·æ±‚å¯ä»¥åŒ…å«é¢å¤–çš„ header ç­‰ä¿¡æ¯ï¼Œç­‰å¾…æœåŠ¡å™¨å“åº”
* è·å–å“åº”å†…å®¹ å¦‚æœæœåŠ¡å™¨èƒ½æ­£å¸¸å“åº”ï¼Œä¼šå¾—åˆ°ä¸€ä¸ª Responseï¼ŒResponse çš„å†…å®¹ä¾¿æ˜¯æ‰€è¦è·å–çš„é¡µé¢å†…å®¹ï¼Œç±»å‹å¯èƒ½æ˜¯ HTML,Json å­—ç¬¦ä¸²ï¼ŒäºŒè¿›åˆ¶æ•°æ®ï¼ˆå›¾ç‰‡æˆ–è€…è§†é¢‘ï¼‰ç­‰ç±»å‹
* è§£æå†…å®¹ å¾—åˆ°çš„å†…å®¹å¯èƒ½æ˜¯ HTML, å¯ä»¥ç”¨æ­£åˆ™è¡¨è¾¾å¼ï¼Œé¡µé¢è§£æåº“è¿›è¡Œè§£æï¼Œå¯èƒ½æ˜¯ Json, å¯ä»¥ç›´æ¥è½¬æ¢ä¸º Json å¯¹è±¡è§£æï¼Œå¯èƒ½æ˜¯äºŒè¿›åˆ¶æ•°æ®ï¼Œå¯ä»¥åšä¿å­˜æˆ–è€…è¿›ä¸€æ­¥çš„å¤„ç†
* ä¿å­˜æ•°æ® ä¿å­˜å½¢å¼å¤šæ ·ï¼Œå¯ä»¥å­˜ä¸ºæ–‡æœ¬ï¼Œä¹Ÿå¯ä»¥ä¿å­˜åˆ°æ•°æ®åº“ï¼Œæˆ–è€…ä¿å­˜ç‰¹å®šæ ¼å¼çš„æ–‡ä»¶

## çŸ¥è¯†ç‚¹

* æ•°æ®è§£æ
* åˆ°æ•°æ®å­˜å‚¨
* æ¨¡æ‹Ÿç™»é™†
* éªŒè¯ç è¯†åˆ«
* ä»£ç†IPä½¿ç”¨
* å¹¶å‘è¯·æ±‚

### çˆ¬è™«åè®®

çˆ¬è™«åè®®å³ç½‘ç«™æ ¹ç›®å½•ä¹‹ä¸‹çš„robots.txtæ–‡ä»¶ï¼Œç”¨æ¥å‘ŠçŸ¥çˆ¬è™«è€…å“ªäº›å¯ä»¥æ‹¿å“ªäº›ä¸èƒ½å·ï¼Œå…¶ä¸­Crawl-delayå‘ŠçŸ¥äº†ç½‘ç«™æœŸæœ›çš„è¢«è®¿é—®çš„é—´éš”ã€‚

### httpè¯·æ±‚åˆ†æ

* è®¿é—®é¡µé¢ï¼š<https://movie.douban.com/subject/6390825/comments?sort=new_score&status=P>
* æŒ‰ä¸‹F12ï¼Œè¿›å…¥networké¢æ¿è¿›è¡Œç½‘ç»œè¯·æ±‚çš„åˆ†æï¼Œé€šè¿‡åˆ·æ–°ç½‘é¡µé‡æ–°è·å¾—è¯·æ±‚ï¼Œå€ŸåŠ©chromeæµè§ˆå™¨å¯¹è¯·æ±‚è¿›è¡Œç­›é€‰ã€åˆ†æï¼Œæ‰¾åˆ°å…ƒç´ ï¼Œå¹¶åˆ†æurlè§„å¾‹

### requestsè¯·æ±‚

* æ¨¡ä»¿å‘é€è¯·æ±‚
* åˆ¤æ–­æ˜¯å¦è·å–è¯·æ±‚æˆåŠŸ

### Xpathè¯­æ³•

å¯¹ç½‘é¡µå†…å®¹è¿›è¡Œè§£æï¼Œå¸¸ç”¨çš„å·¥å…·æœ‰æ­£åˆ™è¡¨è¾¾å¼ã€Beautiful Soupã€Xpathç­‰ç­‰ï¼›å…¶ä¸­Xpathåˆå¿«åˆæ–¹ä¾¿ã€‚

<http://www.runoob.com/xpath/xpath-tutorial.html>

### åŸºç¡€è¯­æ³•

### Pandasæ•°æ®å¤„ç†

## æ­¥éª¤

* ç½‘ç»œè¯·æ±‚åˆ†æ
* ç½‘é¡µå†…å®¹è§£æ
* æ•°æ®è¯»å–å­˜å‚¨

## åçˆ¬è™«

* [luyishisi/Anti-Anti-Spider](https://github.com/luyishisi/Anti-Anti-Spider):è¶Šæ¥è¶Šå¤šçš„ç½‘ç«™å…·æœ‰åçˆ¬è™«ç‰¹æ€§ï¼Œæœ‰çš„ç”¨å›¾ç‰‡éšè—å…³é”®æ•°æ®ï¼Œæœ‰çš„ä½¿ç”¨åäººç±»çš„éªŒè¯ç ï¼Œå»ºç«‹ååçˆ¬è™«çš„ä»£ç ä»“åº“ï¼Œé€šè¿‡ä¸ä¸åŒç‰¹æ€§çš„ç½‘ç«™åšæ–—äº‰ï¼ˆæ— æ¶æ„ï¼‰æé«˜æŠ€æœ¯ã€‚ï¼ˆæ¬¢è¿æäº¤éš¾ä»¥é‡‡é›†çš„ç½‘ç«™ï¼‰ï¼ˆå› å·¥ä½œåŸå› ï¼Œé¡¹ç›®æš‚åœï¼‰ <https://www.urlteam.org>

## å›¾ä¹¦

* çˆ¬è™«å®æˆ˜ï¼šä»æ•°æ®åˆ°äº§å“

## æ•™ç¨‹

* [Python-crawler-tutorial-starts-from-zero](https://github.com/Kr1s77/Python-crawler-tutorial-starts-from-zero):pythonçˆ¬è™«æ•™ç¨‹ï¼Œå¸¦ä½ ä»é›¶åˆ°ä¸€ï¼ŒåŒ…å«jsé€†å‘ï¼Œselenium, tesseract OCRè¯†åˆ«,mongodbçš„ä½¿ç”¨ï¼Œä»¥åŠscrapyæ¡†æ¶
* [Python-crawler](https://github.com/Ehco1996/Python-crawler):ä»å¤´å¼€å§‹ ç³»ç»ŸåŒ–çš„ å­¦ä¹ å¦‚ä½•å†™Pythonçˆ¬è™«ã€‚ Pythonç‰ˆæœ¬ 3.6

## å®ä¾‹

* [chinese-poetry](https://github.com/chinese-poetry/chinese-poetry):æœ€å…¨ä¸­åå¤è¯—è¯æ•°æ®åº“, å”å®‹ä¸¤æœè¿‘ä¸€ä¸‡å››åƒå¤è¯—äºº, æ¥è¿‘5.5ä¸‡é¦–å”è¯—åŠ 26ä¸‡å®‹è¯—. ä¸¤å®‹æ—¶æœŸ1564ä½è¯äººï¼Œ21050é¦–è¯ã€‚ <http://shici.store>
* [tushare](https://github.com/waditu/tushare):TuShare is a utility for crawling historical data of China stocks
* [erret](https://github.com/MontFerret/ferret):Declarative web scraping
* [modood/Administrative-divisions-of-China](https://github.com/modood/Administrative-divisions-of-China):ä¸­åäººæ°‘å…±å’Œå›½è¡Œæ”¿åŒºåˆ’ï¼šçœçº§ï¼ˆçœä»½ç›´è¾–å¸‚è‡ªæ²»åŒºï¼‰ã€ åœ°çº§ï¼ˆåŸå¸‚ï¼‰ã€ å¿çº§ï¼ˆåŒºå¿ï¼‰ã€ ä¹¡çº§ï¼ˆä¹¡é•‡è¡—é“ï¼‰ã€ æ‘çº§ï¼ˆæ‘å§”ä¼šå±…å§”ä¼šï¼‰ ï¼Œä¸­å›½çœå¸‚åŒºé•‡æ‘äºŒçº§ä¸‰çº§å››çº§äº”çº§è”åŠ¨åœ°å€æ•°æ® Node.js çˆ¬è™«ã€‚
* [weixin_crawler](https://github.com/wonderfulsuccess/weixin_crawler):é«˜æ•ˆå¾®ä¿¡å…¬ä¼—å·å†å²æ–‡ç« å’Œé˜…è¯»æ•°æ®çˆ¬è™«powered by scrapy
* [google-images-download](https://github.com/hardikvasa/google-images-download):Python Script to download hundreds of images from 'Google Images'. It is a ready-to-run code!
* [python-spider](https://github.com/Jack-Cherish/python-spider/tree/master/2020):
  rainbowPython3ç½‘ç»œçˆ¬è™«å®æˆ˜ï¼šæ·˜å®ã€äº¬ä¸œã€ç½‘æ˜“äº‘ã€Bç«™ã€12306ã€æŠ–éŸ³ã€ç¬”è¶£é˜ã€æ¼«ç”»å°è¯´ä¸‹è½½ã€éŸ³ä¹ç”µå½±ä¸‹è½½ç­‰ <https://cuijiahua.com/blog/spider/>
* [lianjia-scrawler](https://github.com/XuefengHuang/lianjia-scrawler)

## å·¥å…·

* [html-parser](https://github.com/bupt1987/html-parser):php html parserï¼Œç±»ä¼¼ä¸PHP Simple HTML DOM Parserï¼Œä½†æ˜¯æ¯”å®ƒå¿«å¥½å‡ å€
* [scrape-it](https://github.com/IonicaBizau/scrape-it):ğŸ”® A Node.js scraper for humans. <https://ionicabizau.net/blog/30-how-to-write-a-web-scraper-in-nodejs>
* [gocrawl](https://github.com/PuerkitoBio/gocrawl):Polite, slim and concurrent web crawler.
* [crawlab](https://github.com/crawlab-team/crawlab):Distributed web crawler admin platform for spiders management regardless of languages and frameworks.
* [pyspider](https://github.com/binux/pyspider) A Powerful Spider(Web Crawler) System in Python. <http://docs.pyspider.org/>
