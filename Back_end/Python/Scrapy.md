# [scrapy/scrapy](https://github.com/scrapy/scrapy)

Scrapy, a fast high-level web crawling & scraping framework for Python. https://scrapy.org

## Xpath

```py
# é€‰å–èŠ‚ç‚¹
xpath('//div') # é€‰å–äº†divèŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('/div') # ä»æ ¹èŠ‚ç‚¹ä¸Šé€‰å–divèŠ‚ç‚¹
xpath('//div') # é€‰å–æ‰€æœ‰çš„divèŠ‚ç‚¹
xpath('./div') # é€‰å–å½“å‰èŠ‚ç‚¹ä¸‹çš„divèŠ‚ç‚¹
xpath('..') # å›åˆ°ä¸Šä¸€ä¸ªèŠ‚ç‚¹
xpathï¼ˆ'//@calss'ï¼‰ # é€‰å–æ‰€æœ‰çš„classå±æ€§
xpath('//div|//table') # é€‰å–æ‰€æœ‰çš„divå’ŒtableèŠ‚ç‚¹

## è°“è¯­è¢«åµŒåœ¨æ–¹æ‹¬å·å†…ï¼Œç”¨æ¥æŸ¥æ‰¾æŸä¸ªç‰¹å®šçš„èŠ‚ç‚¹æˆ–åŒ…å«æŸä¸ªåˆ¶å®šçš„å€¼çš„èŠ‚ç‚¹
xpath('/body/div[1]') # é€‰å–bodyä¸‹çš„ç¬¬ä¸€ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[last()]') # é€‰å–bodyä¸‹æœ€åä¸€ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[last()-1]') # é€‰å–bodyä¸‹å€’æ•°ç¬¬äºŒä¸ªdivèŠ‚ç‚¹
xpath('/body/div[positon()<3]') # é€‰å–bodyä¸‹å‰ä¸¤ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[@class]') # é€‰å–bodyä¸‹å¸¦æœ‰classå±æ€§çš„divèŠ‚ç‚¹
xpath('/body/div[@class="main"]') # é€‰å–bodyä¸‹classå±æ€§ä¸ºmainçš„divèŠ‚ç‚¹
xpath('/body/div[price>35.00]') # é€‰å–bodyä¸‹priceå…ƒç´ å€¼å¤§äº35çš„divèŠ‚ç‚¹

## é€šé…ç¬¦
xpathï¼ˆ'/div/*'ï¼‰# é€‰å–divä¸‹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('/div[@*]') # é€‰å–æ‰€æœ‰å¸¦å±æ€§çš„divèŠ‚ç‚¹

# è½´å¯ä»¥å®šä¹‰ç›¸å¯¹äºå½“å‰èŠ‚ç‚¹çš„èŠ‚ç‚¹é›†
path('./ancestor::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å…ˆè¾ˆèŠ‚ç‚¹ï¼ˆçˆ¶ã€ç¥–çˆ¶ï¼‰
xpath('./ancestor-or-self::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å…ˆè¾ˆèŠ‚ç‚¹ä»¥åŠèŠ‚ç‚¹æœ¬èº«
xpath('./attribute::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
xpath('./child::*') # è¿”å›å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('./descendant::*') # è¿”å›å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰åä»£èŠ‚ç‚¹ï¼ˆå­èŠ‚ç‚¹ã€å­™èŠ‚ç‚¹ï¼‰
xpath('./following::*') # é€‰å–æ–‡æ¡£ä¸­å½“å‰èŠ‚ç‚¹ç»“æŸæ ‡ç­¾åçš„æ‰€æœ‰èŠ‚ç‚¹
xpath('./following-sibling::*') # é€‰å–å½“å‰èŠ‚ç‚¹ä¹‹åçš„å…„å¼ŸèŠ‚ç‚¹
xpath('./parent::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹
xpath('./preceding::*') # é€‰å–æ–‡æ¡£ä¸­å½“å‰èŠ‚ç‚¹å¼€å§‹æ ‡ç­¾å‰çš„æ‰€æœ‰èŠ‚ç‚¹
xpath('./preceding-sibling::*') # é€‰å–å½“å‰èŠ‚ç‚¹ä¹‹å‰çš„å…„å¼ŸèŠ‚ç‚¹
xpath('./self::*') # é€‰å–å½“å‰èŠ‚ç‚¹

## åŠŸèƒ½å‡½æ•°
xpath('//div[starts-with(@id,"ma")]') # é€‰å–idå€¼ä»¥maå¼€å¤´çš„divèŠ‚ç‚¹
xpath('//div[contains(@id,"ma")]') # é€‰å–idå€¼åŒ…å«maçš„divèŠ‚ç‚¹
xpath('//div[contains(@id,"ma") and contains(@id,"in")]') # é€‰å–idå€¼åŒ…å«maå’Œinçš„divèŠ‚ç‚¹
xpath('//div[contains(text(),"ma")]') # é€‰å–èŠ‚ç‚¹æ–‡æœ¬åŒ…å«maçš„divèŠ‚ç‚¹
```

## å‚æ•°

`scrapy shell "http://quotes.toscrape.com/page/1/"`
* module
    - crawler    <scrapy.crawler.Crawler object at 0x110f58a50>
    - item       {}
    - request    <GET http://quotes.toscrape.com/page/1/>
    - response   <200 http://quotes.toscrape.com/page/1/>
    - settings   <scrapy.settings.Settings object at 0x110f58ad0>
    - spider     <DefaultSpider 'default' at 0x1112eab50>
* shortcuts
    - fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
    - fetch(req)                  Fetch a scrapy.Request and update local objects
    - shelp()           Shell help (print this help)
    - view(response)    View response in a browser


## å·¥å…·

* [scrapy/quotesbot](https://github.com/scrapy/quotesbot):This is a sample Scrapy project for educational purposes 
* admin UI
    - [DormyMo/SpiderKeeper](https://github.com/DormyMo/SpiderKeeper)ï¼šadmin ui for scrapy/open source scrapinghub http://sk.7mdm.com:5000/

## å‚è€ƒ

* [CriseLYJ/awesome-python-login-model](https://github.com/CriseLYJ/awesome-python-login-model):ğŸ˜®pythonæ¨¡æ‹Ÿç™»é™†ä¸€äº›å¤§å‹ç½‘ç«™ï¼Œè¿˜æœ‰ä¸€äº›ç®€å•çš„çˆ¬è™«
* [Scrapy documentation](https://docs.scrapy.org/en/latest/)
