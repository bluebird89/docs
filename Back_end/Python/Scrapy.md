# [scrapy](https://github.com/scrapy/scrapy)

Scrapy, a fast high-level web crawling & scraping framework for Python. https://scrapy.org

* Scrapy Engine å¼•æ“è´Ÿè´£æ§åˆ¶æ•°æ®æµåœ¨ç³»ç»Ÿä¸­æ‰€æœ‰ç»„ä»¶ä¸­æµåŠ¨ï¼Œå¹¶åœ¨ç›¸åº”åŠ¨ä½œå‘ç”Ÿæ—¶è§¦å‘äº‹ä»¶ã€‚ è¯¦ç»†å†…å®¹æŸ¥çœ‹ä¸‹é¢çš„æ•°æ®æµ (Data Flow) éƒ¨åˆ†ã€‚æ­¤ç»„ä»¶ç›¸å½“äºçˆ¬è™«çš„ â€œå¤§è„‘â€ï¼Œæ˜¯æ•´ä¸ªçˆ¬è™«çš„è°ƒåº¦ä¸­å¿ƒã€‚
* è°ƒåº¦å™¨ (Scheduler) è°ƒåº¦å™¨ä»å¼•æ“æ¥å— request å¹¶å°†ä»–ä»¬å…¥é˜Ÿï¼Œä»¥ä¾¿ä¹‹åå¼•æ“è¯·æ±‚ä»–ä»¬æ—¶æä¾›ç»™å¼•æ“ã€‚ åˆå§‹çš„çˆ¬å– URL å’Œåç»­åœ¨é¡µé¢ä¸­è·å–çš„å¾…çˆ¬å–çš„ URL å°†æ”¾å…¥è°ƒåº¦å™¨ä¸­ï¼Œç­‰å¾…çˆ¬å–ã€‚åŒæ—¶è°ƒåº¦å™¨ä¼šè‡ªåŠ¨å»é™¤é‡å¤çš„ URLï¼ˆå¦‚æœç‰¹å®šçš„ URL ä¸éœ€è¦å»é‡ä¹Ÿå¯ä»¥é€šè¿‡è®¾ç½®å®ç°ï¼Œå¦‚ post è¯·æ±‚çš„ URLï¼‰
* ä¸‹è½½å™¨ (Downloader) ä¸‹è½½å™¨è´Ÿè´£è·å–é¡µé¢æ•°æ®å¹¶æä¾›ç»™å¼•æ“ï¼Œè€Œåæä¾›ç»™ spiderã€‚
* Spiders Spider æ˜¯ Scrapy ç”¨æˆ·ç¼–å†™ç”¨äºåˆ†æ response å¹¶æå– item (å³è·å–åˆ°çš„ item) æˆ–é¢å¤–è·Ÿè¿›çš„ URL çš„ç±»ã€‚ æ¯ä¸ª spider è´Ÿè´£å¤„ç†ä¸€ä¸ªç‰¹å®š (æˆ–ä¸€äº›) ç½‘ç«™ã€‚
* Item Pipeline Item Pipeline è´Ÿè´£å¤„ç†è¢« spider æå–å‡ºæ¥çš„ itemã€‚å…¸å‹çš„å¤„ç†æœ‰æ¸…ç†ã€ éªŒè¯åŠæŒä¹…åŒ– (ä¾‹å¦‚å­˜å–åˆ°æ•°æ®åº“ä¸­)ã€‚ å½“é¡µé¢è¢«çˆ¬è™«è§£ææ‰€éœ€çš„æ•°æ®å­˜å…¥ Item åï¼Œå°†è¢«å‘é€åˆ°é¡¹ç›®ç®¡é“ (Pipeline)ï¼Œå¹¶ç»è¿‡å‡ ä¸ªç‰¹å®šçš„æ¬¡åºå¤„ç†æ•°æ®ï¼Œæœ€åå­˜å…¥æœ¬åœ°æ–‡ä»¶æˆ–å­˜å…¥æ•°æ®åº“ã€‚
* ä¸‹è½½å™¨ä¸­é—´ä»¶ (Downloader middlewares) ä¸‹è½½å™¨ä¸­é—´ä»¶æ˜¯åœ¨å¼•æ“åŠä¸‹è½½å™¨ä¹‹é—´çš„ç‰¹å®šé’©å­ (specific hook)ï¼Œå¤„ç† Downloader ä¼ é€’ç»™å¼•æ“çš„ responseã€‚ å…¶æä¾›äº†ä¸€ä¸ªç®€ä¾¿çš„æœºåˆ¶ï¼Œé€šè¿‡æ’å…¥è‡ªå®šä¹‰ä»£ç æ¥æ‰©å±• Scrapy åŠŸèƒ½ã€‚é€šè¿‡è®¾ç½®ä¸‹è½½å™¨ä¸­é—´ä»¶å¯ä»¥å®ç°çˆ¬è™«è‡ªåŠ¨æ›´æ¢ user-agentã€IP ç­‰åŠŸèƒ½ã€‚
* Spider ä¸­é—´ä»¶ (Spider middlewares) Spider ä¸­é—´ä»¶æ˜¯åœ¨å¼•æ“åŠ Spider ä¹‹é—´çš„ç‰¹å®šé’©å­ (specific hook)ï¼Œå¤„ç† spider çš„è¾“å…¥ (response) å’Œè¾“å‡º (items åŠ requests)ã€‚ å…¶æä¾›äº†ä¸€ä¸ªç®€ä¾¿çš„æœºåˆ¶ï¼Œé€šè¿‡æ’å…¥è‡ªå®šä¹‰ä»£ç æ¥æ‰©å±• Scrapy åŠŸèƒ½ã€‚
* æ•°æ®æµ (Data flow)
  - å¼•æ“æ‰“å¼€ä¸€ä¸ªç½‘ç«™ (open a domain)ï¼Œæ‰¾åˆ°å¤„ç†è¯¥ç½‘ç«™çš„ Spider å¹¶å‘è¯¥ spider è¯·æ±‚ç¬¬ä¸€ä¸ªè¦çˆ¬å–çš„ URL (s)ã€‚
  - å¼•æ“ä» Spider ä¸­è·å–åˆ°ç¬¬ä¸€ä¸ªè¦çˆ¬å–çš„ URL å¹¶åœ¨è°ƒåº¦å™¨ (Scheduler) ä»¥ Request è°ƒåº¦ã€‚
  - å¼•æ“å‘è°ƒåº¦å™¨è¯·æ±‚ä¸‹ä¸€ä¸ªè¦çˆ¬å–çš„ URLã€‚
  - è°ƒåº¦å™¨è¿”å›ä¸‹ä¸€ä¸ªè¦çˆ¬å–çš„ URL ç»™å¼•æ“ï¼Œå¼•æ“å°† URL é€šè¿‡ä¸‹è½½ä¸­é—´ä»¶ (è¯·æ±‚ (request) æ–¹å‘) è½¬å‘ç»™ä¸‹è½½å™¨ (Downloader)
  - ä¸€æ—¦é¡µé¢ä¸‹è½½å®Œæ¯•ï¼Œä¸‹è½½å™¨ç”Ÿæˆä¸€ä¸ªè¯¥é¡µé¢çš„ Responseï¼Œå¹¶å°†å…¶é€šè¿‡ä¸‹è½½ä¸­é—´ä»¶ (è¿”å› (response) æ–¹å‘) å‘é€ç»™å¼•æ“ã€‚
  - å¼•æ“ä»ä¸‹è½½å™¨ä¸­æ¥æ”¶åˆ° Response å¹¶é€šè¿‡ Spider ä¸­é—´ä»¶ (è¾“å…¥æ–¹å‘) å‘é€ç»™ Spider å¤„ç†ã€‚
  - Spider å¤„ç† Response å¹¶è¿”å›çˆ¬å–åˆ°çš„ Item åŠ (è·Ÿè¿›çš„) æ–°çš„ Request ç»™å¼•æ“ã€‚
  - å¼•æ“å°† (Spider è¿”å›çš„) çˆ¬å–åˆ°çš„ Item ç»™ Item Pipelineï¼Œå°† (Spider è¿”å›çš„) Request ç»™è°ƒåº¦å™¨ã€‚
  - (ä»ç¬¬äºŒæ­¥) é‡å¤ç›´åˆ°è°ƒåº¦å™¨ä¸­æ²¡æœ‰æ›´å¤šåœ° requestï¼Œå¼•æ“å…³é—­è¯¥ç½‘ç«™ã€‚

## Xpath

```py
# é€‰å–èŠ‚ç‚¹
xpath('//div') # é€‰å–äº†divèŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('/div') # ä»æ ¹èŠ‚ç‚¹ä¸Šé€‰å–divèŠ‚ç‚¹
xpath('//div') # é€‰å–æ‰€æœ‰çš„divèŠ‚ç‚¹
xpath('./div') # é€‰å–å½“å‰èŠ‚ç‚¹ä¸‹çš„divèŠ‚ç‚¹
xpath('..') # å›åˆ°ä¸Šä¸€ä¸ªèŠ‚ç‚¹
xpathï¼ˆ'//@calss'ï¼‰ # é€‰å–æ‰€æœ‰çš„classå±æ€§
xpath('//div|//table') # é€‰å–æ‰€æœ‰çš„divå’ŒtableèŠ‚ç‚¹

## è°“è¯­è¢«åµŒåœ¨æ–¹æ‹¬å·å†…ï¼Œç”¨æ¥æŸ¥æ‰¾æŸä¸ªç‰¹å®šçš„èŠ‚ç‚¹æˆ–åŒ…å«æŸä¸ªåˆ¶å®šçš„å€¼çš„èŠ‚ç‚¹
xpath('/body/div[1]') # é€‰å–bodyä¸‹çš„ç¬¬ä¸€ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[last()]') # é€‰å–bodyä¸‹æœ€åä¸€ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[last()-1]') # é€‰å–bodyä¸‹å€’æ•°ç¬¬äºŒä¸ªdivèŠ‚ç‚¹
xpath('/body/div[positon()<3]') # é€‰å–bodyä¸‹å‰ä¸¤ä¸ªdivèŠ‚ç‚¹
xpath('/body/div[@class]') # é€‰å–bodyä¸‹å¸¦æœ‰classå±æ€§çš„divèŠ‚ç‚¹
xpath('/body/div[@class="main"]') # é€‰å–bodyä¸‹classå±æ€§ä¸ºmainçš„divèŠ‚ç‚¹
xpath('/body/div[price>35.00]') # é€‰å–bodyä¸‹priceå…ƒç´ å€¼å¤§äº35çš„divèŠ‚ç‚¹

## é€šé…ç¬¦
xpathï¼ˆ'/div/*'ï¼‰# é€‰å–divä¸‹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('/div[@*]') # é€‰å–æ‰€æœ‰å¸¦å±æ€§çš„divèŠ‚ç‚¹

# è½´å¯ä»¥å®šä¹‰ç›¸å¯¹äºå½“å‰èŠ‚ç‚¹çš„èŠ‚ç‚¹é›†
path('./ancestor::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å…ˆè¾ˆèŠ‚ç‚¹ï¼ˆçˆ¶ã€ç¥–çˆ¶ï¼‰
xpath('./ancestor-or-self::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å…ˆè¾ˆèŠ‚ç‚¹ä»¥åŠèŠ‚ç‚¹æœ¬èº«
xpath('./attribute::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å±æ€§
xpath('./child::*') # è¿”å›å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰å­èŠ‚ç‚¹
xpath('./descendant::*') # è¿”å›å½“å‰èŠ‚ç‚¹çš„æ‰€æœ‰åä»£èŠ‚ç‚¹ï¼ˆå­èŠ‚ç‚¹ã€å­™èŠ‚ç‚¹ï¼‰
xpath('./following::*') # é€‰å–æ–‡æ¡£ä¸­å½“å‰èŠ‚ç‚¹ç»“æŸæ ‡ç­¾åçš„æ‰€æœ‰èŠ‚ç‚¹
xpath('./following-sibling::*') # é€‰å–å½“å‰èŠ‚ç‚¹ä¹‹åçš„å…„å¼ŸèŠ‚ç‚¹
xpath('./parent::*') # é€‰å–å½“å‰èŠ‚ç‚¹çš„çˆ¶èŠ‚ç‚¹
xpath('./preceding::*') # é€‰å–æ–‡æ¡£ä¸­å½“å‰èŠ‚ç‚¹å¼€å§‹æ ‡ç­¾å‰çš„æ‰€æœ‰èŠ‚ç‚¹
xpath('./preceding-sibling::*') # é€‰å–å½“å‰èŠ‚ç‚¹ä¹‹å‰çš„å…„å¼ŸèŠ‚ç‚¹
xpath('./self::*') # é€‰å–å½“å‰èŠ‚ç‚¹

## åŠŸèƒ½å‡½æ•°
xpath('//div[starts-with(@id,"ma")]') # é€‰å–idå€¼ä»¥maå¼€å¤´çš„divèŠ‚ç‚¹
xpath('//div[contains(@id,"ma")]') # é€‰å–idå€¼åŒ…å«maçš„divèŠ‚ç‚¹
xpath('//div[contains(@id,"ma") and contains(@id,"in")]') # é€‰å–idå€¼åŒ…å«maå’Œinçš„divèŠ‚ç‚¹
xpath('//div[contains(text(),"ma")]') # é€‰å–èŠ‚ç‚¹æ–‡æœ¬åŒ…å«maçš„divèŠ‚ç‚¹
```

## å‚æ•°

`scrapy shell "http://quotes.toscrape.com/page/1/"`

* module
  - crawler    <scrapy.crawler.Crawler object at 0x110f58a50>
  - item       {}
  - request    <GET http://quotes.toscrape.com/page/1/>
  - response   <200 http://quotes.toscrape.com/page/1/>
  - settings   <scrapy.settings.Settings object at 0x110f58ad0>
  - spider     <DefaultSpider 'default' at 0x1112eab50>
* shortcuts
  - fetch(url[, redirect=True]) Fetch URL and update local objects (by default, redirects are followed)
  - fetch(req)                  Fetch a scrapy.Request and update local objects
  - shelp()           Shell help (print this help)
  - view(response)    View response in a browser

## å·¥å…·

* [scrapy/quotesbot](https://github.com/scrapy/quotesbot):This is a sample Scrapy project for educational purposes
* admin UI
  - [DormyMo/SpiderKeeper](https://github.com/DormyMo/SpiderKeeper)ï¼šadmin ui for scrapy/open source scrapinghub http://sk.7mdm.com:5000/

## å‚è€ƒ

* [CriseLYJ/awesome-python-login-model](https://github.com/CriseLYJ/awesome-python-login-model):ğŸ˜®pythonæ¨¡æ‹Ÿç™»é™†ä¸€äº›å¤§å‹ç½‘ç«™ï¼Œè¿˜æœ‰ä¸€äº›ç®€å•çš„çˆ¬è™«
* [Scrapy documentation](https://docs.scrapy.org/en/latest/)
