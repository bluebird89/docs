# log

## åŸç†

* å†™æ—¥å¿—æ–¹å¼ï¼Œæ–‡ä»¶
* åˆ†ç±»
* æ§åˆ¶å¼€å…³

## ELK(ElasticSearch, Logstash, Kibana)


```sh
# JDK  æ”¾åœ¨è·¯å¾„/usr/local/java ç¼–è¾‘é…ç½®æ–‡ä»¶ /etc/profile
export JAVA_HOME=/usr/local/java/jdk1.8.0_77
export PATH=$JAVA_HOME/bin:$PATH
java -version

# æ­å»º ElasticSearch
wget https://download.elasticsearch.org/elasticsearch/release/org/elasticsearch/distribution/tar/elasticsearch/2.1.0/elasticsearch-2.1.0.tar.gz
tar xf elasticsearch-2.1.0.tar.gz
cd /usr/local/elasticsearch-2.1.0/bin
./plugin  -install mobz/elasticsearch-head  # webé›†ç¾¤ç®¡ç†æ’ä»¶  å®‰è£…å¥½äº†ä»¥åå¯ä»¥åœ¨pluginæ–‡ä»¶å‘ç°å¤šäº†ä¸€ä¸ªhead
./elasticsearch  -Des.insecure.allow.root=true  #åŠ è¿™ä¸ªå‚æ•°æ‰å¯ä»¥rootå¯åŠ¨

curl -X GET 192.168.88.250:9200   #curl æµ‹è¯•
{
 "name" : "Reeva Payge",
 "cluster_name" : "elasticsearch",
 "version" : {
   "number" : "2.1.0",
   "build_hash" : "72cd1f1a3eee09505e036106146dc1949dc5dc87",
   "build_timestamp" : "2015-11-18T22:40:03Z",
   "build_snapshot" : false,
   "lucene_version" : "5.3.1"
 },
 "tagline" : "You Know, for Search"
}
# webåœ°å€  http://192.168.88.250:9200/_plugin/head/

# nginx
wget   æ­å»ºnginxä¹‹å‰éœ€è¦å®‰è£… pcre
tar xf nginx-1.7.8.tar.gz
cd /usr/local/nginx
vim /usr/local/nginx/conf/nginx.conf

#user  nobody;
worker_processes  1;

#error_log  logs/error.log  notice;
#error_log  logs/error.log  info;

#pid        logs/nginx.pid;

events {
  worker_connections  1024;
}

http {

    upstream kibana4 {  #å¯¹Kibanaåšä»£ç†
           server 127.0.0.1:5601 fail_timeout=0;
    }
   include       mime.types;
   default_type  application/octet-stream;

   #log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
   #                  '$status $body_bytes_sent "$http_referer" '
   #                  '"$http_user_agent" "$http_x_forwarded_for"';

    log_format json '{"@timestamp":"$time_iso8601",'   #é…ç½®NGINXçš„æ—¥å¿—æ ¼å¼ json
                       '"host":"$server_addr",'
                       '"clientip":"$remote_addr",'
                       '"size":$body_bytes_sent,'
                       '"responsetime":$request_time,'
                       '"upstreamtime":"$upstream_response_time",'
                       '"upstreamhost":"$upstream_addr",'
                       '"http_host":"$host",'
                       '"url":"$uri",'
                       '"xff":"$http_x_forwarded_for",'
                       '"referer":"$http_referer",'
                       '"agent":"$http_user_agent",'
                       '"status":"$status"}';
    access_log /var/log/nginx/access.log_json json;   #é…ç½®æ—¥å¿—è·¯å¾„ jsonæ ¼å¼
    error_log /var/log/nginx/error.log;

   sendfile        on;
   #tcp_nopush     on;

   #keepalive_timeout  0;
   keepalive_timeout  65;

   #gzip  on;

   server {
       listen       80;
       server_name  localhost;

       #charset koi8-r;

       #access_log  logs/host.access.log  main;

       location / {
           root   html;
           index  index.html index.htm;
       }

       #error_page  404              /404.html;

       # redirect server error pages to the static page /50x.html
       #
       error_page   500 502 503 504  /50x.html;
       location = /50x.html {
           root   html;
       }

       # proxy the PHP scripts to Apache listening on 127.0.0.1:80
       #
       #location ~ \.php$ {
       #    proxy_pass   http://127.0.0.1;
       #}

       # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
       #
       #location ~ \.php$ {
       #    root           html;
       #    fastcgi_pass   127.0.0.1:9000;
       #    fastcgi_index  index.php;
       #    fastcgi_param  SCRIPT_FILENAME  /scripts$fastcgi_script_name;
       #    include        fastcgi_params;
       #}

       # deny access to .htaccess files, if Apache's document root
       # concurs with nginx's one
       #
       #location ~ /\.ht {
       #    deny  all;
       #}
   }



   # another virtual host using mix of IP-, name-, and port-based configuration
   #
   #server {
   #    listen       8000;
   #    listen       somename:8080;
   #    server_name  somename  alias  another.alias;

   #    location / {
   #        root   html;
   #        index  index.html index.htm;
   #    }
   #}


   # HTTPS server
   #
   #server {
   #    listen       443 ssl;
   #    server_name  localhost;

   #    ssl_certificate      cert.pem;
   #    ssl_certificate_key  cert.key;

   #    ssl_session_cache    shared:SSL:1m;
   #    ssl_session_timeout  5m;

   #    ssl_ciphers  HIGH:!aNULL:!MD5;
   #    ssl_prefer_server_ciphers  on;

   #    location / {
   #        root   html;
   #        index  index.html index.htm;
   #    }
   #}

server {
   listen               *:80;
   server_name          kibana_server;
   access_log           /var/log/nginx/kibana.srv-log-dev.log;
   error_log            /var/log/nginx/kibana.srv-log-dev.error.log;


   location / {
       root   /var/www/kibana;
       index  index.html  index.htm;
   }

   location ~ ^/kibana4/.* {
       proxy_pass           http://kibana4;
       rewrite             ^/kibana4/(.*)  /$1 break;
       proxy_set_header     X-Forwarded-For $proxy_add_x_forwarded_for;
       proxy_set_header     Host            $host;
       auth_basic           "Restricted";
       auth_basic_user_file /etc/nginx/conf.d/kibana.myhost.org.htpasswd;
   }

}
}

## æ­å»º Logstash
wget https://download.elastic.co/logstash/logstash/logstash-2.1.1.tar.gz
tar xf logstash-2.1.1.tar.gz
cd /usr/local/logstash-2.1.1/bin
vim stdin.conf #ç¼–å†™é…ç½®æ–‡ä»¶
input{
       file {
               path => "/var/log/nginx/access.log_json"  #NGINXæ—¥å¿—åœ°å€ jsonæ ¼å¼
              codec => "json"  jsonç¼–ç 
       }
}
filter {
       mutate {
               split => ["upstreamtime", ","]
       }
       mutate {
               convert => ["upstreamtime", "float"]
       }
}
output{

       elasticsearch {
               hosts => ["192.168.88.250:9200"]   #elasticsearchåœ°å€
               index => "logstash-%{type}-%{+YYYY.MM.dd}"   #ç´¢å¼•
               document_type => "%{type}"
               workers => 1
               flush_size => 20000        #ä¼ è¾“æ•°é‡ é»˜è®¤500
               idle_flush_time => 10      #ä¼ è¾“ç§’æ•°  é»˜è®¤1ç§’
               template_overwrite => true
       }
}
./logstash -f stdin.conf &  #åå°å¯åŠ¨
# å¯åŠ¨æˆåŠŸä»¥å æ‰“å¼€åˆšæ‰æ­å»ºçš„webæœåŠ¡å™¨  eså°±èƒ½çœ‹åˆ°æ•°æ®

# æ­å»ºKibana
wget https://download.elastic.co/kibana/kibana/kibana-4.3.1-linux-x64.tar.gz
tar xf kibana-4.3.1-linux-x64.tar.gz
cd /usr/local/kibana-4.3.1-linux-x64/
vim ./config/kibana.yml

elasticsearch.url: #   åªéœ€è¦ä¿®æ”¹URLä¸ºElasticSearchçš„IPåœ°å€
./kibana& åå°å¯åŠ¨
# å¯åŠ¨æˆåŠŸä»¥å ä¼šç›‘å¬ 5601ç«¯å£

# å¯ä»¥ç”¨KibanaæŸ¥çœ‹ åœ°å€ : 192.168.88.250:5601
# createç°è‰²çš„ è¯´æ˜æ²¡æœ‰åˆ›å»ºç´¢å¼•  æ‰“å¼€ä½ çš„nginxæœåŠ¡å™¨ åˆ·æ–°å‡ ä¸‹ é‡‡é›†ä¸€ä¸‹æ•°æ® ç„¶å  é€‰æ‹© å·¦ä¸Šè§’çš„ Discover
# æ•°æ®å¯èƒ½ä¼šå‡ºä¸æ¥ é‚£æ˜¯å› ä¸º Kibana æ˜¯æ ¹æ®æ—¶é—´æ¥åŒ¹é…çš„ å¹¶ä¸” å› ä¸º Logstashçš„é‡‡é›†æ—¶é—´ä½¿ç”¨çš„UTC  æ°¸è¿œæ—©8ä¸ªå°æ—¶ æ‰€ä»¥è®¾ç½®æ—¶é—´ è¦è®¾ç½®æ™š8ä¸ªå°æ—¶ä»¥å
```

## å·¥å…·

* [Graylog2/graylog2-server](https://github.com/Graylog2/graylog2-server):Free and open source log management https://www.graylog.org/
* [klaussinani/signale](https://github.com/klaussinani/signale):ğŸ‘‹ Hackable console logger
