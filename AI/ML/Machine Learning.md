# Machine learning

ç ”ç©¶è®¡ç®—æœºæ€æ ·æ¨¡æ‹Ÿæˆ–å®ç°äººç±»çš„å­¦ä¹ è¡Œä¸ºï¼Œä»¥è·å–æ–°çš„çŸ¥è¯†æˆ–æŠ€èƒ½ï¼Œé‡æ–°ç»„ç»‡å·²æœ‰çš„çŸ¥è¯†ç»“æ„ä½¿ä¹‹ä¸æ–­æ”¹å–„è‡ªèº«çš„æ€§èƒ½ã€‚å®ƒæ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œæ˜¯ä½¿è®¡ç®—æœºå…·æœ‰æ™ºèƒ½çš„æ ¹æœ¬é€”å¾„ï¼Œå…¶åº”ç”¨éåŠäººå·¥æ™ºèƒ½çš„å„ä¸ªé¢†åŸŸï¼Œå®ƒä¸»è¦ä½¿ç”¨å½’çº³ã€ç»¼åˆè€Œä¸æ˜¯æ¼”è¯‘ã€‚åœ¨è¿‡å»çš„åå¹´ä¸­ï¼Œæœºå™¨å­¦ä¹ å¸®åŠ©æˆ‘ä»¬è‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼Œæœ‰æ•ˆçš„è¯­éŸ³è¯†åˆ«ï¼Œæœ‰æ•ˆçš„ç½‘ç»œæœç´¢ï¼Œå¹¶æå¤§åœ°æé«˜äº†äººç±»åŸºå› ç»„çš„è®¤è¯†ã€‚æœºå™¨å­¦ä¹ æ˜¯å½“ä»Šéå¸¸æ™®éï¼Œä½ å¯èƒ½ä¼šä½¿ç”¨è¿™ä¸€å¤©å‡ åå€è€Œä¸è‡ªçŸ¥ã€‚å¾ˆå¤šç ”ç©¶è€…ä¹Ÿè®¤ä¸ºè¿™æ˜¯æœ€å¥½çš„äººå·¥æ™ºèƒ½çš„å–å¾—æ–¹å¼ã€‚åœ¨æœ¬è¯¾ä¸­ï¼Œæ‚¨å°†å­¦ä¹ æœ€æœ‰æ•ˆçš„æœºå™¨å­¦ä¹ æŠ€æœ¯ï¼Œå¹¶è·å¾—å®è·µï¼Œè®©å®ƒä»¬ä¸ºè‡ªå·±çš„å·¥ä½œã€‚æ›´é‡è¦çš„æ˜¯ï¼Œä½ ä¼šä¸ä»…å¾—åˆ°ç†è®ºåŸºç¡€çš„å­¦ä¹ ï¼Œè€Œä¸”è·å¾—é‚£äº›éœ€è¦å¿«é€Ÿå’Œå¼ºå¤§çš„åº”ç”¨æŠ€æœ¯è§£å†³é—®é¢˜çš„å®ç”¨æŠ€æœ¯ã€‚æœ€åï¼Œä½ ä¼šå­¦åˆ°ä¸€äº›ç¡…è°·åˆ©ç”¨æœºå™¨å­¦ä¹ å’Œäººå·¥æ™ºèƒ½çš„æœ€ä½³å®è·µåˆ›æ–°ã€‚

* æœºå™¨å­¦ä¹ æ„å‘³ç€ï¼šä»æ•°æ®ä¸­å­¦ä¹ 
* ä¸»è¦å…³ä¹ç®—æ³•ä¸æ•°æ®ï¼Œå°¤å…¶æ˜¯æ•°æ®;:å¯ä»¥æ²¡æœ‰å¤æ‚çš„ç®—æ³•ï¼Œä½†ä¸èƒ½æ²¡æœ‰å¥½çš„æ•°æ®ã€‚
* é™¤éä½ æœ‰è®¸å¤šæ•°æ®ï¼Œå¦åˆ™ä½ åº”è¯¥åšæŒä½¿ç”¨ç®€å•çš„æ¨¡å‹:åŸºäºæ•°æ®è¯†åˆ«æ¨¡å¼ï¼Œæ„å»ºç”±å‚æ•°å®šä¹‰çš„æ¨¡å‹ã€‚å¦‚æœä½ çš„å‚æ•°å®šä¹‰è¿‡å¤šï¼Œä½ å¾ˆå®¹æ˜“è¿‡åº¦æ‹Ÿåˆã€‚è¯¦ç»†çš„è§£é‡Šéœ€è¦æ›´å¤šæ•°å­¦çŸ¥è¯†ï¼Œä½†æ˜¯æœºå™¨å­¦ä¹ çš„åŸåˆ™æ˜¯ï¼šå°½å¯èƒ½ä½¿æ¨¡å‹ç®€å•ã€‚
* æœºå™¨å­¦ä¹ çš„æ€§èƒ½å—åˆ°è¾“å…¥æ•°æ®è´¨é‡é™åˆ¶:"æ— ç”¨è¾“å…¥ï¼Œæ— ç”¨è¾“å‡º"å·§å¦™åœ°ç‚¹æ˜äº†æœºå™¨å­¦ä¹ çš„å…³é”®ï¼Œæœºå™¨å­¦ä¹ åªèƒ½å‘ç°è¾“å…¥æ•°æ®ä¸­çš„æ¨¡å¼ã€‚å¯¹äºæœ‰ç›‘ç£çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ï¼Œä¾‹å¦‚åˆ†ç±»ï¼Œè¾“å…¥æ•°æ®å¿…é¡»æ ‡è®°æ­£ç¡®ï¼Œç‰¹å¾æ˜æ˜¾ã€‚
* æœºå™¨å­¦ä¹ éœ€è¦å…·æœ‰ä»£è¡¨æ€§çš„æ•°æ®:è¿‡å»çš„è¡¨ç°ä¸å¯¹æœªæ¥ç»“æœä½œä¿è¯ã€‚æœºå™¨å­¦ä¹ åˆ™åªèƒ½å¯¹ä¸è®­ç»ƒæ•°æ®åˆ†å¸ƒç›¸åŒçš„æ ·æœ¬å¤–æœ‰è‰¯å¥½æ•ˆæœã€‚å› æ­¤ï¼Œåº”å¯¹è®­ç»ƒæ•°æ®å’Œæ ·æœ¬å¤–æ•°æ®çš„åç¦»è¡¨ç¤ºè­¦è§‰ï¼Œç»å¸¸æ€§åœ°é‡æ–°è®­ç»ƒä½ çš„æ¨¡å‹ä»¥å…å¤±æ•ˆã€‚
* æœºå™¨å­¦ä¹ ä¸­å¤§éƒ¨åˆ†çš„å›°éš¾å·¥ä½œä¸ºæ•°æ®è½¬æ¢:ç”¨äºæ•°æ®æ¸…æ´—å’Œç‰¹å¾å·¥ç¨‹ï¼ˆå°†åŸå§‹ç‰¹å¾è½¬åŒ–ä¸ºæ›´æœ‰ä»£è¡¨æ€§çš„ç‰¹å¾ï¼‰ä¸Šã€‚
* æ·±åº¦å­¦ä¹ å°†ä¸€äº›ä¼ ç»Ÿéœ€è¦ç‰¹å¾å·¥ç¨‹çš„å·¥ä½œè‡ªåŠ¨åŒ–è¿›è¡Œï¼Œç‰¹åˆ«æ˜¯åœ¨å›¾åƒå’Œè§†é¢‘é¢†åŸŸã€‚ä½†æ˜¯æ·±åº¦å­¦ä¹ å¹¶ä¸æ˜¯ä¸€ç§æ–°æŠ€æœ¯ï¼Œä»ç„¶éœ€è¦åœ¨æ•°æ®æ¸…ç†å’Œè½¬åŒ–æ–¹é¢ä»˜å‡ºå·¨å¤§çš„åŠªåŠ›ã€‚
* æœºå™¨å­¦ä¹ ç³»ç»Ÿææ˜“å—æ“ä½œè€…è¯¯å·®å½±å“:æœºå™¨å­¦ä¹ ç®—æ³•ä¸ä¼šæ€æ­»äººï¼Œåªæœ‰äººä¼šæ€æ­»äººã€‚å½“æœºå™¨å­¦ä¹ ç®—æ³•ç³»ç»Ÿå¥”æºƒæ—¶ï¼Œä¸€èˆ¬å¾ˆå°‘æ˜¯ç”±äºæœºå™¨å­¦ä¹ ç®—æ³•é”™è¯¯ã€‚è€Œæ˜¯å› ä¸ºå¤§å¤šæ•°æ—¶å€™ï¼Œä½ åœ¨è®­ç»ƒæ•°æ®ä¸­å¼•è¿›äº†äººä¸ºè¯¯å·®ï¼Œæˆ–è€…ä¸€äº›ç³»ç»Ÿè¯¯å·®ã€‚æ‰€ä»¥ï¼Œæ°¸è¿œä¿æŒè´¨ç–‘ã€‚
* æœºå™¨å­¦ä¹ å¯ä»¥æ¼«ä¸å°½å¿ƒåœ°åˆ›é€ è‡ªæˆ‘å®ç°çš„é¢„è¨€:ä½ ä»Šå¤©åšçš„å†³å®šå°†å½±å“æ˜å¤©æ”¶é›†çš„è®­ç»ƒæ•°æ®ã€‚ä¸€æ—¦æœºå™¨å­¦ä¹ ç³»ç»Ÿä¸­åµŒå…¥åå·®ï¼Œå®ƒå°±ä¼šç”Ÿæˆæ›´å¤šæ–°çš„æ•°æ®å¼ºåŒ–è¿™äº›åå·®ï¼Œæœ‰ä¸€äº›åå·®ä¼šæ¯æ‰äººçš„ç”Ÿæ´»ã€‚è´Ÿè´£ä»»ä¸€ç‚¹ï¼šä¸è¦åˆ›é€ å¯è‡ªæˆ‘å®ç°çš„é¢„è¨€ã€‚
* AIä¸ä¼šæ‹¥æœ‰è‡ªæˆ‘æ„è¯†ï¼Œä¸ç”¨æ‹…å¿ƒå´›èµ·å¹¶æ¯ç­äººç±»

## ç†è®º

* å­¦ä¹ å®ƒä»¬çš„æ¨¡å‹å‡½æ•°ã€ç›®æ ‡å‡½æ•°ï¼Œä»æ¨¡å‹å‡½æ•°åˆ°ç›®æ ‡å‡½æ•°çš„è¿ç®—è¿‡ç¨‹ï¼Œå„ä¸ªå‡½æ•°ç›¸åº”çš„ç‰©ç†æ„ä¹‰ï¼Œæœ€ä¼˜åŒ–çš„æ–¹æ³•
* å†ä¸ç‰¹å¾å·¥ç¨‹ç»“åˆ

## é—®é¢˜

* ä¸šåŠ¡ä¸Šè¦è§£å†³ä»€ä¹ˆé—®é¢˜
* è¯¥é—®é¢˜æ¶‰åŠåˆ°çš„ä¿¡æ¯ç®¡é“æœ‰å“ªäº›
* å¦‚ä½•é‡‡é›†æ•°æ®ï¼Œæ•°æ®æºåœ¨å“ª
* æ•°æ®æ˜¯å®Œæ•´çš„å—ï¼Œæ•°æ®åˆ»åº¦æœ€å°æ˜¯å¤šå°‘
* æ•°æ®æ˜¯å®šæœŸå‘å¸ƒçš„è¿˜æ˜¯å®æ—¶è·å–çš„
* ç¡®å®šå½±å“æ¨¡å‹çš„æœ‰ä»·å€¼å› ç´ 
* å·¥ä½œé‡

## æ•°æ®

* å¾…æ”¶é›†çš„æ•°æ®å¯èƒ½æ˜¯è¡¨æ ¼æ•°æ®ã€ä¸€ä¸²å®æ—¶æ•°æ®ï¼ŒNç»´çŸ©é˜µæˆ–å…¶ä»–ç±»å‹æ•°æ®ï¼ŒåŒæ—¶ä¹Ÿå¯èƒ½æ˜¯å¤šç§å­˜å‚¨ä»‹è´¨ï¼Œé€šè¿‡ETLå¤„ç†å°†æ··åˆçš„æ•°æ®æºè½¬æˆæˆ‘ä»¬éœ€è¦çš„æ ¼å¼ï¼Œç”Ÿæˆç»“æ„åŒ–æ•°æ®ç±»å‹ã€‚
- å¯¹äºæ”¶é›†çš„æ•°æ®ï¼Œå¯èƒ½å­˜åœ¨ç¼ºé™·ï¼Œæ¯”å¦‚ç©ºå€¼ã€å¼‚å¸¸å€¼æˆ–æ•°æ®äº§ç”Ÿå™¨æœ¬èº«å¼•èµ·çš„åå·®ã€‚è¿™äº›ç¼ºé™·å¯èƒ½å¯¼è‡´æ¨¡å‹æ•ˆæœä¸ä½³ï¼ŒåŒæ—¶ä¸ºäº†ä¼˜åŒ–æ›´å¿«æ”¶æ•›ï¼Œéœ€è¦åšæ•°æ®æ ‡å‡†åŒ–å¤„ç†ï¼Œæ‰€ä»¥éœ€è¦è¿›è¡Œæ•°æ®é¢„å¤„ç†ã€‚
    * æ¯”å¦‚ç¼ºå¤±å€¼å¯ä»¥ç®€å•è®¾ä¸º0ã€åˆ—å¹³å‡å€¼ã€ä¸­å€¼ã€æœ€é«˜é¢‘ç‡å€¼ã€ç”šè‡³æ˜¯ç¨³å¥ç®—æ³•å’Œknnç­‰ç­‰ã€‚
    * æ¯”å¦‚æ ‡å‡†åŒ–æ•°æ®é›†ï¼Œä½¿æ•°æ®é›†æ­£æ€åˆ†å¸ƒï¼Œå¹³å‡å€¼ä¸º0æ ‡å‡†å·®ä¸º1ã€‚è€Œä¸”è¿˜è¾¾åˆ°äº†ç‰¹å¾ç¼©æ”¾æ•ˆæœã€‚

## æ¨¡å‹å®šä¹‰

æœºå™¨å­¦ä¹ ä¸»è¦å°±æ˜¯æ¨¡å‹é—®é¢˜ï¼Œæˆ‘ä»¬é€šè¿‡æœºå™¨å­¦ä¹ æ¥å¯¹ç°å®è¿›è¡ŒæŠ½è±¡å»ºæ¨¡ï¼Œä»¥è§£å†³ç°å®é—®é¢˜ã€‚æ‰€ä»¥æœºå™¨å­¦ä¹ ä¸»è¦å·¥ä½œå°±æ˜¯ä½¿ç”¨å“ªç§æ¨¡å‹æ¥å»ºæ¨¡ï¼Œå°½ç®¡å„ç§å¤§å¤§å°å°æ¨¡å‹ä¸€å¤§å †ï¼Œä½†å¤§ä½“ä¸Šä¹Ÿæœ‰äº›å¥—è·¯ã€‚

* å›å½’é—®é¢˜ï¼šé¢„æµ‹ç»“æœ
* åˆ†ç±»é—®é¢˜ï¼šå¯¹æ•°æ®è¿›è¡Œåˆ†ç±»
  * ç›‘ç£å­¦ä¹ ï¼šéœ€è¦æ•°æ®æ ‡è®°
  * å¦åˆ™æ˜¯éç›‘ç£å­¦ä¹ ï¼Œä½¿ç”¨èšç±»æŠ€æœ¯ã€‚
* æ•°æ®æ˜¯å¦ä¸ºè¿ç»­çš„ï¼Œæ˜¯çš„è¯è€ƒè™‘åºåˆ—æ¨¡å‹ï¼Œæ¯”å¦‚è‡ªå›å½’å’ŒRNNä¹‹ç±»çš„ã€‚
* å°½é‡ä½¿ç”¨ç®€å•æ¨¡å‹ï¼Œå¦‚æœèƒ½ç”¨æ¯”å¦‚ç”¨å•å˜é‡æˆ–å¤šå˜é‡çš„çº¿æ€§å›å½’æˆ–é€»è¾‘å›å½’ã€‚
* ç®€å•æ¨¡å‹è§£å†³ä¸äº†çš„æƒ…å†µï¼Œå¯é€šè¿‡å¤šå±‚ç¥ç»ç½‘ç»œè§£å†³ï¼Œæ¯”å¦‚å¤æ‚çš„éçº¿æ€§ã€‚
* ä½¿ç”¨äº†å¤šå°‘ä¸ªç»´åº¦çš„å˜é‡ï¼Œå°†ä½œç”¨å¤§çš„ç‰¹å¾æå–å‡ºæ¥ï¼Œå¹¶æŠŠä¸é‡è¦çš„ç‰¹å¾å»æ‰ï¼Œæ¯”å¦‚ç”¨PCAé™ç»´ã€‚
* ä¸æ˜¯ç›‘ç£ä¹Ÿä¸æ˜¯éç›‘ç£ï¼Ÿè€ƒè™‘å¼ºåŒ–å­¦ä¹ 

## æŸå¤±å‡½æ•°

æŸå¤±å‡½æ•°ç”¨äºè¡¡é‡æ¨¡å‹è´¨é‡ï¼Œå®ƒå¯ä»¥åº¦é‡æ¨¡å‹é¢„æµ‹å€¼ä¸å®é™…æœŸæœ›ä¹‹é—´çš„å·®è·ï¼Œé€‰æ‹©ä¸åˆé€‚çš„å‡½æ•°å¯èƒ½ä¼šå½±å“æ¨¡å‹çš„å‡†ç¡®æ€§ï¼Œç”šè‡³å½±å“æ”¶æ•›é€Ÿåº¦ã€‚

## æ¨¡å‹è®­ç»ƒ

* è¿­ä»£ï¼Œè¡¨ç¤ºæ¨¡å‹è®¡ç®—å’Œè°ƒæ•´çš„ä¸€æ¬¡è¿‡ç¨‹ï¼›
* æ‰¹ï¼Œæ•°æ®é›†æ¯æ¬¡ä»¥ä¸€æ‰¹ä¸ºå•ä½è¾“å…¥åˆ°æ¨¡å‹ä¸­ï¼›
* epochï¼Œæ¯å½“æ•´ä¸ªæ•°æ®é›†è¢«å¤„ç†å®Œç§°ä¸ºä¸€ä¸ªepochã€‚

## æ•°æ®åˆ†å‰²

ä¸€èˆ¬å°†æ•´ä¸ªæ•°æ®é›†åˆ†æˆä¸‰ç»„ï¼Œæ¯”ä¾‹æ˜¯7:2:1

* ç¬¬ä¸€ç»„ä¸ºè®­ç»ƒé›†ï¼Œç”¨äºè°ƒæ•´æ¨¡å‹å‚æ•°ï¼›
* ç¬¬äºŒç§ä¸ºéªŒè¯é›†ï¼Œç”¨äºæ¯”è¾ƒå¤šä¸ªæ¨¡å‹ç›´æ¥çš„è¡¨ç°ï¼›
* ç¬¬ä¸‰ç»„ä¸ºæµ‹è¯•é›†ï¼Œç”¨äºæµ‹è¯•è®­ç»ƒå¾—åˆ°çš„æ¨¡å‹å‡†ç¡®æ€§ã€‚

## æ¨¡å‹æ•ˆæœ

æ¨¡å‹è®­ç»ƒå®Œåè¦çœ‹æ•ˆæœå¦‚ä½•ï¼Œè¦çœ‹çœ‹æ³›åŒ–çš„èƒ½åŠ›ã€‚

* å¯¹äºå›å½’é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢å‡ ä¸ªæŒ‡æ ‡æ¥äº†è§£æ‹Ÿåˆæ•ˆæœã€‚
  - å¹³å‡ç»å¯¹è¯¯å·®
  - ä¸­å€¼ç»å¯¹è¯¯å·®
  - å‡æ–¹è¯¯å·®ç­‰ç­‰
* å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢å‡ ä¸ªæŒ‡æ ‡æ¥äº†è§£åˆ†ç±»æ•ˆæœã€‚
  - å‡†ç¡®æ€§
  - ç²¾ç¡®ç‡
  - å¬å›ç‡
  - Få€¼
  - æ··æ·†çŸ©é˜µ
* å¯¹äºèšç±»é—®é¢˜ï¼Œå¯ä»¥é€šè¿‡ä¸‹é¢å‡ ä¸ªæŒ‡æ ‡æ¥äº†è§£èšç±»æ•ˆæœã€‚
  - è½®å»“ç³»æ•°
  - åŒè´¨æ€§
  - å®Œæ•´æ€§
  - Våº¦é‡

## è¯¾ç¨‹åˆ—è¡¨

* æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€
    - æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€
        + å‡½æ•°ä¸æ•°æ®çš„æ³›åŒ–
        + æ¨ç†ä¸å½’çº³ (Deduction and Induction)
    - çº¿æ€§ä»£æ•°ï¼ˆLinear Algebraï¼‰
        + å‘é‡ä¸çŸ©é˜µ (Vector and Matrix)
        + ç‰¹å¾å€¼ä¸ç‰¹å¾å‘é‡
        + å‘é‡ä¸é«˜ç»´ç©ºé—´
        + ç‰¹å¾å‘é‡ï¼ˆFeature Vectorï¼‰
    - æ¦‚ç‡ä¸ç»Ÿè®¡ï¼ˆProbability and Statisticsï¼‰
        + æ¡ä»¶æ¦‚ç‡ä¸ç»å…¸é—®é¢˜ (Conditional Probability)
        + è¾¹ç¼˜æ¦‚ç‡ (Marginal Probability)
    - ä½œä¸š/å®è·µï¼š è´¢å®é—®é¢˜çš„æ¦‚ç‡è®¡ç®—ç¨‹åº
* æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€
   - ç»Ÿè®¡æ¨ç†ï¼ˆStatistical Inferenceï¼‰
        + è´å¶æ–¯åŸç†ä¸æ¨ç† (Bayesian Theorem)
        + æå¤§ä¼¼ç„¶ä¼°è®¡ (Maximum Likelihood)
        + ä¸»è§‚æ¦‚ç‡ï¼ˆSubjective Probabilityï¼‰
        + æœ€å¤§åå»¶æ¦‚ç‡ï¼ˆMAP)
   - éšæœºå˜é‡ï¼ˆRandom Variableï¼‰
        + ç‹¬ç«‹ä¸ç›¸å…³ (Independence)
        + å‡å€¼ä¸æ–¹å·® ï¼ˆMean and Varianceï¼‰
        + åæ–¹å·® (Co-Variance)
   - æ¦‚ç‡åˆ†å¸ƒï¼ˆProbability Distributions)
   - ä¸­å¿ƒæé™å®šç†ï¼ˆCentral Limit Theorem)
   - ä½œä¸š/å®è·µï¼š æ¦‚ç‡åˆ†å¸ƒé‡‡æ ·ä¸ä¸åŒéšæœºå˜é‡ä¹‹é—´åæ–¹å·®è®¡ç®—
* æœºå™¨å­¦ä¹ çš„æ•°å­¦åŸºç¡€
   - æ¢¯åº¦ä¸‹é™ï¼ˆGradient Descentï¼‰
        + å¯¼æ•°ä¸æ¢¯åº¦ï¼ˆDerivative and Gradientï¼‰
        + éšæœºæ¢¯åº¦ä¸‹é™ï¼ˆSGDï¼‰
        + ç‰›é¡¿æ–¹æ³•ï¼ˆNewton's Method)
   - å‡¸å‡½æ•°ï¼ˆConvex Functionï¼‰
        + Jensenä¸ç­‰å¼ï¼ˆJensen's Inequalityï¼‰
        + æ‹‰æ ¼æœ—æ—¥ä¹˜å­ï¼ˆLagrange Multiplierï¼‰
   - ä½œä¸š/å®è·µï¼š åˆ©ç”¨ç‰›é¡¿æ–¹æ³•æ±‚è§£ç»™å®šçš„æ–¹ç¨‹
* æœºå™¨å­¦ä¹ çš„å“²å­¦ï¼ˆPhilosophy of MLï¼‰
   - ç®—æ³•çš„ç§‘å­¦ï¼ˆScience of Algorithmsï¼‰
        + è¾“å…¥ä¸è¾“å‡ºçš„ç¥è¯ï¼ˆMystery of I/Oï¼‰
        + å¥¥å¡å§†å‰ƒåˆ€ï¼ˆOccamâ€™s Razorï¼‰
   - ç»´æ•°çš„è¯…å’’ï¼ˆCurse of Dimensionalityï¼‰
        + é«˜ç»´çš„å‡ ä½•ç‰¹æ€§ (Geometric Properity )
        + é«˜ç»´ç©ºé—´æµå½¢ï¼ˆHigh-dimensional Manifoldï¼‰
   - æœºå™¨å­¦ä¹ ä¸äººå·¥æ™ºèƒ½ï¼ˆMachine learning and AIï¼‰
   - æœºå™¨å­¦ä¹ çš„èŒƒå¼ï¼ˆParadigms of MLï¼‰
* ç»å…¸æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆClassical ML Modelsï¼‰
   - æ ·æœ¬å­¦ä¹ ï¼ˆCase-Based Reasoningï¼‰
        + K-è¿‘é‚»ï¼ˆK-Nearest Neighborsï¼‰
        + K-è¿‘é‚»é¢„æµ‹ï¼ˆKNN for Predictionï¼‰
        + è·ç¦»ä¸æµ‹åº¦ï¼ˆDistance and Metricï¼‰
   - æœ´ç´ è´å¶æ–¯ï¼ˆNaÃ¯ve Bayes Classifier)
        + æ¡ä»¶ç‹¬ç«‹ï¼ˆConditional Independenceï¼‰
        + åˆ†ç±»ï¼ˆNaive Bayes for Classification)
   - ä½œä¸š/å®è·µï¼šåƒåœ¾é‚®ä»¶åˆ†ç±»çš„æ¡ˆä¾‹
* ç»å…¸æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆClassical ML Modelsï¼‰
   - å†³ç­–æ ‘ï¼ˆDecision Tree Learningï¼‰
         + ä¿¡æ¯è®ºä¸æ¦‚ç‡
         + ä¿¡æ¯ç†µï¼ˆInformation Entropyï¼‰
         + ID3
   - é¢„æµ‹æ ‘ï¼ˆCARTï¼‰
         - GiniæŒ‡æ ‡ï¼ˆGini Indexï¼‰
         - å†³ç­–æ ‘ä¸è§„åˆ™ï¼ˆDT and Rule Learningï¼‰
   - ä½œä¸š/å®è·µï¼šå†³ç­–æ ‘åˆ†ç±»å®éªŒ
* ç»å…¸æœºå™¨å­¦ä¹ æ¨¡å‹ï¼ˆClassical ML Modelsï¼‰
   - é›†æˆå­¦ä¹ ï¼ˆEnsemble learningï¼‰
        + Bagging and Boosting
        + AdaBoost
        + è¯¯å·®åˆ†è§£ï¼ˆBias-Variance Decompositionï¼‰
        + éšæœºæ£®æ—ï¼ˆBoosting and Random Forestï¼‰
   + æ¨¡å‹è¯„ä¼°ï¼ˆModel Evaluationï¼‰
        + äº¤å‰éªŒè¯ï¼ˆCross-Validationï¼‰
        + ROC (Receiver Operating Characteristics)
        + Cost-Sensitive Learning
   - ä½œä¸š/å®è·µï¼šéšæœºæ£®æ—ä¸å†³ç­–æ ‘åˆ†ç±»å®éªŒçš„æ¯”è¾ƒ
* çº¿æ€§æ¨¡å‹ï¼ˆLinear Modelsï¼‰
   - çº¿æ€§æ¨¡å‹ï¼ˆLinear Modelsï¼‰
        + çº¿æ€§æ‹Ÿåˆï¼ˆLinear Regressionï¼‰
   - æœ€å°äºŒä¹˜æ³•ï¼ˆLMSï¼‰
        + çº¿æ€§åˆ†ç±»å™¨ï¼ˆLinear Classifierï¼‰
   - æ„ŸçŸ¥å™¨ï¼ˆPerceptronï¼‰
   - å¯¹æ•°å‡ ç‡å›å½’ï¼ˆLogistic Regressionï¼‰
   - çº¿æ€§æ¨¡å‹çš„æ¦‚ç‡è§£é‡Š (Probabilistic Interpretation)
   - ä½œä¸š/å®è·µï¼šå¯¹æ•°å‡ ç‡å›å½’çš„æ–‡æœ¬æƒ…æ„Ÿåˆ†æä¸­åº”ç”¨
* çº¿æ€§æ¨¡å‹ï¼ˆLinear Modelsï¼‰
   - çº¿æ€§åˆ¤åˆ«åˆ†æ (Linear Discrimination Analysis)
   - çº¦æŸçº¿æ€§æ¨¡å‹ (Linear Model with Regularization)
         + LASSO
         + Ridge Regression
   - ç¨€ç–è¡¨ç¤ºä¸å­—å…¸å­¦ä¹ 
         + Sparse Representation & Coding
         + Dictionary Learning
* æ ¸æ–¹æ³•ï¼ˆKernel Methodsï¼‰
   - æ”¯æŒå‘é‡æœºSVMï¼ˆSupport Vector Machinesï¼‰
        + VC-ç»´ï¼ˆVC-Dimensionï¼‰
        + æœ€å¤§é—´è·ï¼ˆMaximum Marginï¼‰
        + æ”¯æ’‘å‘é‡ï¼ˆSupport Vectorsï¼‰
   - ä½œä¸š/å®è·µï¼šSVMä¸åŒæ ¸å‡½æ•°åœ¨å®é™…åˆ†ç±»ä¸­æ¯”è¾ƒ
* æ ¸æ–¹æ³•ï¼ˆKernel Methodsï¼‰
   - å¯¹å¶æ‹‰æ ¼æœ—æ—¥ä¹˜å­
   - KKTæ¡ä»¶ï¼ˆKKT Conditionsï¼‰
   - Support Vector Regression (SVR)
   - æ ¸æ–¹æ³•ï¼ˆKernel Methodsï¼‰
* ç»Ÿè®¡å­¦ä¹ ï¼ˆStatistical Learningï¼‰
   - åˆ¤åˆ«æ¨¡å‹ä¸ç”Ÿæˆæ¨¡å‹
        + éšå«å˜é‡ï¼ˆLatent Variableï¼‰
   - æ··åˆæ¨¡å‹ï¼ˆMixture Modelï¼‰
        + ä¸‰æšç¡¬å¸é—®é¢˜ï¼ˆ3-Coin Problemï¼‰
        + é«˜æ–¯æ··åˆæ¨¡å‹ï¼ˆGaussian Mixture Modelï¼‰
   - EMç®—æ³•ï¼ˆExpectation Maximizationï¼‰
        + æœŸæœ›æœ€å¤§ï¼ˆExpectation Maximizationï¼‰
        + æ··åˆæ¨¡å‹çš„EMç®—æ³•ï¼ˆEM for Mixture Modelsï¼‰
        + Jensen ä¸ç­‰å¼ (Jensen's Inequality)
        + EMç®—æ³•æ¨å¯¼ä¸æ€§èƒ½ (EM Algorithm)
* ç»Ÿè®¡å­¦ä¹ ï¼ˆStatistical Learningï¼‰
   - éšé©¬å¯å¤«æ¨¡å‹ï¼ˆHidden Markov Modelsï¼‰
        + åŠ¨æ€æ··åˆæ¨¡å‹ï¼ˆDynamic Mixture Modelï¼‰
        + ç»´ç‰¹æ¯”ç®—æ³•ï¼ˆViterbi Algorithmï¼‰
        + ç®—æ³•æ¨å¯¼ (Algorithm)
   - æ¡ä»¶éšæœºåœºï¼ˆConditional Random Fieldï¼‰
* ç»Ÿè®¡å­¦ä¹ ï¼ˆStatistical Learningï¼‰
    - å±‚æ¬¡å›¾æ¨¡å‹ï¼ˆHierarchical Bayesian Modelï¼‰
        + æ¦‚ç‡å›¾æ¨¡å‹ (Graphical Model)
        + ä»éšå«è¯­ä¹‰æ¨¡å‹åˆ°p-LSA (From LSA to P-LSA)
        + Dirichlet åˆ†å¸ƒä¸ç‰¹ç‚¹ï¼ˆDirichlet Distributionï¼‰
        + å¯¹å¶åˆ†å¸ƒï¼ˆConjugate Distributionï¼‰
* ç»Ÿè®¡å­¦ä¹ ï¼ˆStatistical Learningï¼‰
    - ä¸»é¢˜æ¨¡å‹ï¼ˆTopic Model â€“ LDAï¼‰
        + Latent Dirichlet Allocation
        + æ–‡æœ¬åˆ†ç±»ï¼ˆLDA for Text Classificationï¼‰
   - ä¸­æ–‡ä¸»é¢˜æ¨¡å‹ï¼ˆTopic Modeling for Chineseï¼‰
   - å…¶ä»–ä¸»é¢˜æ¨¡å‹ï¼ˆOther Topic Variablesï¼‰
* æ— ç›‘ç£å­¦ä¹ ï¼ˆUnsupervised Learningï¼‰
   - K-å‡å€¼ç®—æ³•ï¼ˆK-Meansï¼‰
        + æ ¸å¯†åº¦ä¼°è®¡ï¼ˆKernel Density Estimationï¼‰
        + å±‚æ¬¡èšç±»ï¼ˆHierarchical Clusteringï¼‰
   - è’™ç‰¹å¡æ´›(Monte Carlo)
        + è’™ç‰¹å¡æ´›æ ‘æœç´¢ï¼ˆMonte Carol Tree Searchï¼‰
        + MCMCï¼ˆMarkov Chain Monte Carloï¼‰
        + Gibbs Sampling
* æµå½¢å­¦ä¹ ï¼ˆManifold Learningï¼‰
   - ä¸»æˆåˆ†åˆ†æï¼ˆPCAï¼‰
        + PCA and ICA
   - ä½ç»´åµŒå…¥ï¼ˆLow-Dimensional Embeddingï¼‰
        + ç­‰åº¦é‡æ˜ å°„ï¼ˆIsomapï¼‰
        + å±€éƒ¨çº¿æ€§åµŒå…¥ï¼ˆLocally Linear Embeddingï¼‰
* æ¦‚å¿µå­¦ä¹ ï¼ˆConcept Learningï¼‰
   - æ¦‚å¿µå­¦ä¹ ï¼ˆConcept Learningï¼‰
        + ç»å…¸æ¦‚å¿µå­¦ä¹ 
        + One-Shortæ¦‚å¿µå­¦ä¹ 
   - é«˜æ–¯è¿‡ç¨‹å­¦ä¹ ï¼ˆGaussian Process for MLï¼‰
        + Dirichlet Process
* å¼ºåŒ–å­¦ä¹ ï¼ˆReinforcement Learningï¼‰
    - å¥–èµä¸æƒ©ç½šï¼ˆReward and Penaltyï¼‰
        + çŠ¶æ€ç©ºé—´ (State-Space Model)
        + Q-å­¦ä¹ ç®—æ³• (Q-Learning)
   - è·¯å¾„è§„åˆ’ ï¼ˆPath Planningï¼‰
   - æ¸¸æˆäººå·¥æ™ºèƒ½ ï¼ˆGame AIï¼‰
   - ä½œä¸š/å®è·µï¼šå°é¸Ÿé£è¡Œæ¸¸æˆçš„è‡ªåŠ¨å­¦ä¹ ç®—æ³•
* ç¥ç»ç½‘ç»œ
   - å¤šå±‚ç¥ç»ç½‘ç»œ
        + éçº¿æ€§æ˜ å°„ï¼ˆNonlinear Mappingï¼‰
        + åå‘ä¼ æ’­ï¼ˆBack-propagationï¼‰
   - è‡ªåŠ¨ç¼–ç å™¨ï¼ˆAuto-Encoderï¼‰

## æ•™ç¨‹

* [learnml/machine-learning-specialization](https://github.com/learnml/machine-learning-specialization)
* [ICT-BDA/EasyML](https://github.com/ICT-BDA/EasyML):Easy Machine Learning is a general-purpose dataflow-based system for easing the process of applying machine learning algorithms to real world tasks.
* [kubeflow/kubeflow](https://github.com/kubeflow/kubeflow):Machine Learning Toolkit for Kubernetes
* [Avik-Jain/100-Days-Of-ML-Code](https://github.com/Avik-Jain/100-Days-Of-ML-Code):100 Days of ML Coding
* [llSourcell/Learn_Machine_Learning_in_3_Months](https://github.com/llSourcell/Learn_Machine_Learning_in_3_Months):This is the code for "Learn Machine Learning in 3 Months" by Siraj Raval on Youtube
* [æœºå™¨å­¦ä¹ ï¼ˆMachine Learningï¼‰- å´æ©è¾¾ï¼ˆAndrew Ngï¼‰](https://www.bilibili.com/video/av9912938)
  - [æ–¯å¦ç¦å¤§å­¦2014ï¼ˆå´æ©è¾¾ï¼‰æœºå™¨å­¦ä¹ æ•™ç¨‹ä¸­æ–‡ç¬”è®°](https://www.coursera.org/course/ml)
  - [æ–¯å¦ç¦å¤§å­¦æœºå™¨å­¦ä¹ è¯¾ç¨‹](http://open.163.com/special/opencourse/machinelearning.html)
  - [Andrew Ng è€å¸ˆçš„ æœºå™¨å­¦ä¹ è¯¾ç¨‹](http://coursegraph.com/coursera-machine-learning) http://coursegraph.com/coursera_ml
  - Machine Learning Yearning
  - [fengdu78/Coursera-ML-AndrewNg-Notes](https://github.com/fengdu78/Coursera-ML-AndrewNg-Notes):å´æ©è¾¾è€å¸ˆçš„æœºå™¨å­¦ä¹ è¯¾ç¨‹ä¸ªäººç¬”è®°
* [æå®æ¯…Machine Learning ](https://www.bilibili.com/video/av15889450)
* [æå®æ¯…æœºå™¨å­¦ä¹ (2017)](https://www.bilibili.com/video/av10590361/)
* [æœºå™¨å­¦ä¹ ä¸­çš„æ•°å­¦åŸºç¡€](https://www.bilibili.com/video/av15673238/)
* [afshinea/stanford-cs-229-machine-learning](https://github.com/afshinea/stanford-cs-229-machine-learning):VIP cheatsheets for Stanford's CS 229 Machine Learning
* [Doraemonzzz/ML-Foundation-and-ML-Techniques](https://github.com/Doraemonzzz/ML-Foundation-and-ML-Techniques):å°å¤§æœºå™¨å­¦ä¹ è¯¾ç¨‹ä½œä¸šè¯¦è§£
* [DeqianBai/Your-first-machine-learning-Project---End-to-End-in-Python](https://github.com/DeqianBai/Your-first-machine-learning-Project---End-to-End-in-Python):è¿™æ˜¯ä¸€ä¸ªå®Œæ•´çš„ï¼Œç«¯åˆ°ç«¯çš„æœºå™¨å­¦ä¹ é¡¹ç›®ï¼Œéå¸¸é€‚åˆæœ‰ä¸€å®šåŸºç¡€åæ‹¿æ¥ç»ƒä¹ ï¼Œä»¥æé«˜å¯¹å®Œæ•´æœºå™¨å­¦ä¹ é¡¹ç›®çš„è®¤è¯†
* [Doraemonzzz/Learning-from-data](https://github.com/Doraemonzzz/Learning-from-data):è®°å½•Learning from dataä¸€ä¹¦ä¸­çš„ä¹ é¢˜è§£ç­” http://amlbook.com/

## å‚è€ƒ

* [josephmisiti/awesome-machine-learning](https://github.com/josephmisiti/awesome-machine-learning)A curated list of awesome Machine Learning frameworks, libraries and software.
* [ZuzooVn/machine-learning-for-software-engineers](https://github.com/ZuzooVn/machine-learning-for-software-engineers):A complete daily plan for studying to become a machine learning engineer.
* [airbnb/aerosolve](https://github.com/airbnb/aerosolve):A machine learning package built for humans. http://airbnb.github.io/aerosolve/
* [ageron/handson-ml](https://github.com/ageron/handson-ml):A series of Jupyter notebooks that walk you through the fundamentals of Machine Learning and Deep Learning in python using Scikit-Learn and TensorFlow.
* [hangtwenty/dive-into-machine-learning](https://github.com/hangtwenty/dive-into-machine-learning):Dive into Machine Learning with Python Jupyter notebook and scikit-learn! http://hangtwenty.github.io/dive-into-machine-learning/
* [wizardforcel/nyu-mlif-notes](https://github.com/wizardforcel/nyu-mlif-notes):ğŸ“– NYU é‡‘èæœºå™¨å­¦ä¹  ä¸­æ–‡ç¬”è®°
* [mlflow/mlflow](https://github.com/mlflow/mlflow):Open source platform for the machine learning lifecycle https://mlflow.org
* [zhaozhengcoder/Machine-Learning](https://github.com/zhaozhengcoder/Machine-Learning)ï¼šå…³äºæœºå™¨å­¦ä¹ çš„å†…å®¹
* [GokuMohandas/practicalAI](https://github.com/GokuMohandas/practicalAI):A practical approach to learning machine learning.

## å·¥å…·

* [guess-js/guess](https://github.com/guess-js/guess):Libraries & tools for enabling Machine Learning driven user-experiences on the web
* [gorgonia/gorgonia](https://github.com/gorgonia/gorgonia):Gorgonia is a library that helps facilitate machine learning in Go.
* [ray-project/ray](https://github.com/ray-project/ray):A system for parallel and distributed Python that unifies the ML ecosystem. https://ray.readthedocs.io/en/latest/
* [google/jax](https://github.com/google/jax):GPU- and TPU-backed NumPy with differentiation and JIT compilation.
* [guess-js/guess](https://github.com/guess-js/guess):Libraries & tools for enabling Machine Learning driven user-experiences on the web https://guess-js.github.io/
* [Core ML](link)
